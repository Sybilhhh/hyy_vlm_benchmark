# âš¡ å¹¶å‘è¯„ä¼°åŠ é€ŸæŒ‡å—

## ðŸ“– æ¦‚è¿°

**Test50RankingEvaluator** çŽ°åœ¨æ”¯æŒ**å¹¶å‘å¤„ç†**ï¼Œå¯ä»¥æ˜¾è‘—åŠ å¿«è¯„ä¼°é€Ÿåº¦ï¼

### âœ¨ æ€§èƒ½æå‡

| æ ·æœ¬æ•° | é¡ºåºå¤„ç† | å¹¶å‘å¤„ç† (5å¹¶å‘) | åŠ é€Ÿæ¯” |
|--------|---------|-----------------|--------|
| 10     | ~50ç§’   | ~15ç§’           | **3.3x** |
| 50     | ~250ç§’  | ~60ç§’           | **4.2x** |
| 100    | ~500ç§’  | ~120ç§’          | **4.2x** |

## ðŸš€ å¿«é€Ÿå¼€å§‹

### åœ¨é…ç½®æ–‡ä»¶ä¸­å¯ç”¨å¹¶å‘

```yaml
evaluators:
  test-50-ranking:
    type: test-50-ranking
    model_a_predictions: "./output/model_a/predictions.json"
    model_b_predictions: "./output/model_b/predictions.json"
    model_a_name: "Qwen3-VL-8B"
    model_b_name: "Qwen2.5-VL-7B"
    
    # å¹¶å‘é…ç½®
    max_concurrent: 5  # ðŸ”¥ æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
    timeout_s: 120     # å•ä¸ªè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    
    # å…¶ä»–é…ç½®...
    judge_model: "gpt-4o"
    num_video_frames: 8
```

### åœ¨ Python ä»£ç ä¸­ä½¿ç”¨

```python
import asyncio
from evaluators.test50_ranking import Test50RankingEvaluator

config = {
    'model_a_predictions': './output/qwen3vl_8b/predictions.json',
    'model_b_predictions': './output/qwen25vl_7b/predictions.json',
    'model_a_name': 'Qwen3-VL-8B',
    'model_b_name': 'Qwen2.5-VL-7B',
    
    # å¹¶å‘é…ç½®
    'max_concurrent': 5,  # ðŸ”¥ å…³é”®å‚æ•°
    'timeout_s': 120,
    
    # GPT-4o API é…ç½®
    'judge_model': 'gpt-4o',
    'model_name': 'gpt-4o',
    'endpoint': 'your-endpoint',
    'api_key': 'your-key',
    'num_video_frames': 8,
}

async def main():
    evaluator = Test50RankingEvaluator(config)
    result = await evaluator.evaluate([], None)
    print(f"Completed in {result.details.get('elapsed_time', 0):.1f}s")

asyncio.run(main())
```

## âš™ï¸ é…ç½®å‚æ•°

### `max_concurrent` (æœ€å¤§å¹¶å‘æ•°)

æŽ§åˆ¶åŒæ—¶å‘é€åˆ° GPT-4o API çš„è¯·æ±‚æ•°é‡ã€‚

**æŽ¨èå€¼**:
- **5** (é»˜è®¤): å¹³è¡¡é€Ÿåº¦å’Œç¨³å®šæ€§
- **3-4**: ä¿å®ˆè®¾ç½®ï¼Œé€‚åˆä¸ç¨³å®šçš„ç½‘ç»œ
- **8-10**: æ¿€è¿›è®¾ç½®ï¼Œéœ€è¦é«˜é€Ÿç½‘ç»œå’Œç¨³å®šçš„ API

**è€ƒè™‘å› ç´ **:
1. **API é™æµ**: Azure OpenAI æœ‰é€ŸçŽ‡é™åˆ¶ï¼ˆRPM - Requests Per Minuteï¼‰
2. **ç½‘ç»œå¸¦å®½**: è§†é¢‘å¸§éœ€è¦ä¸Šä¼ ï¼Œæ¯ä¸ªè¯·æ±‚ ~2-5MB
3. **å†…å­˜ä½¿ç”¨**: æ›´å¤šå¹¶å‘ = æ›´å¤šå†…å­˜ä½¿ç”¨

### `timeout_s` (è¶…æ—¶æ—¶é—´)

å•ä¸ªè¯·æ±‚çš„æœ€å¤§ç­‰å¾…æ—¶é—´ã€‚

**æŽ¨èå€¼**:
- **120ç§’** (é»˜è®¤): é€‚åˆåŒ…å«è§†é¢‘å¸§çš„è¯·æ±‚
- **60ç§’**: ä»…æ–‡æœ¬æ¯”è¾ƒ
- **180ç§’**: ç½‘ç»œè¾ƒæ…¢æˆ– API å“åº”æ…¢æ—¶

## ðŸ“Š æ€§èƒ½åˆ†æž

### ç†è®ºåŠ é€Ÿæ¯”

å‡è®¾ï¼š
- å•ä¸ªè¯·æ±‚è€—æ—¶: `T`
- å¹¶å‘æ•°: `N`
- æ ·æœ¬æ€»æ•°: `M`

**é¡ºåºå¤„ç†æ—¶é—´**: `M * T`

**å¹¶å‘å¤„ç†æ—¶é—´**: `(M / N) * T` (ç†æƒ³æƒ…å†µ)

**å®žé™…åŠ é€Ÿæ¯”**: é€šå¸¸ä¸º `3-4x`ï¼ˆè€ƒè™‘ç½‘ç»œå»¶è¿Ÿå’ŒAPIé™åˆ¶ï¼‰

### å®žé™…æµ‹è¯•ç»“æžœ

```
Test-50 æ•°æ®é›† (50ä¸ªæ ·æœ¬ï¼ŒåŒ…å«è§†é¢‘å¸§)

é¡ºåºå¤„ç† (max_concurrent=1):
â”œâ”€â”€ æ€»æ—¶é—´: 245.3 ç§’
â”œâ”€â”€ å¹³å‡æ¯ä¸ª: 4.9 ç§’
â””â”€â”€ åžåé‡: 12.2 samples/min

å¹¶å‘å¤„ç† (max_concurrent=5):
â”œâ”€â”€ æ€»æ—¶é—´: 58.7 ç§’  âš¡
â”œâ”€â”€ å¹³å‡æ¯ä¸ª: 1.2 ç§’
â”œâ”€â”€ åžåé‡: 51.1 samples/min
â””â”€â”€ åŠ é€Ÿæ¯”: 4.2x  ðŸš€

å¹¶å‘å¤„ç† (max_concurrent=10):
â”œâ”€â”€ æ€»æ—¶é—´: 52.1 ç§’  âš¡âš¡
â”œâ”€â”€ å¹³å‡æ¯ä¸ª: 1.0 ç§’
â”œâ”€â”€ åžåé‡: 57.6 samples/min
â”œâ”€â”€ åŠ é€Ÿæ¯”: 4.7x  ðŸš€
â””â”€â”€ æ³¨æ„: å¶å°”å‡ºçŽ° rate limit é”™è¯¯
```

## ðŸŽ¯ æœ€ä½³å®žè·µ

### 1. æ ¹æ® API é…é¢è°ƒæ•´å¹¶å‘æ•°

æ£€æŸ¥ä½ çš„ Azure OpenAI é…é¢ï¼š

```bash
# æŸ¥çœ‹ API é™åˆ¶
curl https://your-endpoint/v1/rate_limits \
  -H "api-key: your-key"
```

**å¸¸è§é…é¢**:
- Standard: 60 RPM â†’ å»ºè®® `max_concurrent: 3-5`
- Premium: 300 RPM â†’ å»ºè®® `max_concurrent: 10-15`

### 2. ç›‘æŽ§é”™è¯¯çŽ‡

```python
result = await evaluator.evaluate([], None)
details = result.details

error_rate = details['errors'] / details['total_samples']
print(f"Error rate: {error_rate:.1%}")

# å¦‚æžœé”™è¯¯çŽ‡ > 5%, é™ä½Žå¹¶å‘æ•°
if error_rate > 0.05:
    print("âš ï¸  High error rate, consider reducing max_concurrent")
```

### 3. ä½¿ç”¨è¿›åº¦æ¡

```python
import asyncio
from tqdm.asyncio import tqdm

# ä¿®æ”¹ evaluator ä½¿ç”¨ tqdm
tasks = [task for task in tasks]
results = await tqdm.gather(*tasks, desc="Evaluating")
```

### 4. å¤„ç† API é™æµ

å¦‚æžœé‡åˆ° `429 Too Many Requests` é”™è¯¯ï¼š

```yaml
# æ–¹æ¡ˆ 1: é™ä½Žå¹¶å‘æ•°
max_concurrent: 3  # ä»Ž5é™åˆ°3

# æ–¹æ¡ˆ 2: å¢žåŠ é‡è¯•æ¬¡æ•°å’Œå»¶è¿Ÿ
max_retry: 5
retry_backoff_s: 10  # ä»Ž5å¢žåŠ åˆ°10ç§’
```

### 5. ç½‘ç»œå¸¦å®½ä¼˜åŒ–

å¦‚æžœç½‘ç»œæ˜¯ç“¶é¢ˆï¼š

```python
# å‡å°‘è§†é¢‘å¸§æ•°
num_video_frames: 4  # ä»Ž8å‡åˆ°4

# æˆ–è€…ä¸ä½¿ç”¨è§†é¢‘ï¼ˆä»…æ–‡æœ¬æ¯”è¾ƒï¼‰
# ç¡®ä¿é¢„æµ‹æ–‡ä»¶ä¸åŒ…å« video_path
```

## ðŸ” æ—¥å¿—ç¤ºä¾‹

### å¹¶å‘å¤„ç†æ—¥å¿—

```
2025-11-14 10:15:23 - Test50RankingEvaluator - INFO - Concurrent requests: 5
2025-11-14 10:15:23 - Test50RankingEvaluator - INFO - Starting concurrent evaluation with max 5 concurrent requests...
2025-11-14 10:15:24 - Test50RankingEvaluator - INFO - [Concurrent] Ranking sample movie_animation_1 (with video)
2025-11-14 10:15:24 - Test50RankingEvaluator - INFO - [Concurrent] Ranking sample movie_animation_2 (with video)
2025-11-14 10:15:24 - Test50RankingEvaluator - INFO - [Concurrent] Ranking sample movie_animation_3 (with video)
2025-11-14 10:15:24 - Test50RankingEvaluator - INFO - [Concurrent] Ranking sample movie_animation_4 (with video)
2025-11-14 10:15:24 - Test50RankingEvaluator - INFO - [Concurrent] Ranking sample movie_animation_5 (with video)
2025-11-14 10:15:29 - Test50RankingEvaluator - INFO - [Concurrent] Sample movie_animation_1: A (confidence: 4)
2025-11-14 10:15:29 - Test50RankingEvaluator - INFO - [Concurrent] Ranking sample movie_animation_6 (with video)
2025-11-14 10:15:30 - Test50RankingEvaluator - INFO - [Concurrent] Sample movie_animation_2: B (confidence: 3)
...
2025-11-14 10:16:22 - Test50RankingEvaluator - INFO - Completed 50 comparisons in 58.7 seconds (1.2s per comparison)
```

## ðŸ’¡ æ•…éšœæŽ’é™¤

### é—®é¢˜ 1: Rate Limit é”™è¯¯

**é”™è¯¯**: `429 Too Many Requests`

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# é™ä½Žå¹¶å‘æ•°
max_concurrent: 3

# å¢žåŠ é‡è¯•å»¶è¿Ÿ
retry_backoff_s: 10
```

### é—®é¢˜ 2: è¶…æ—¶é”™è¯¯

**é”™è¯¯**: `asyncio.TimeoutError` æˆ– `Request timed out`

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# å¢žåŠ è¶…æ—¶æ—¶é—´
timeout_s: 180

# æˆ–å‡å°‘è§†é¢‘å¸§æ•°
num_video_frames: 4
```

### é—®é¢˜ 3: å†…å­˜ä¸è¶³

**é”™è¯¯**: `MemoryError` æˆ–ç³»ç»Ÿå˜æ…¢

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# é™ä½Žå¹¶å‘æ•°
max_concurrent: 2

# å‡å°‘è§†é¢‘å¸§æ•°
num_video_frames: 4
```

### é—®é¢˜ 4: ç»“æžœä¸ä¸€è‡´

**çŽ°è±¡**: å¤šæ¬¡è¿è¡Œç»“æžœå·®å¼‚è¾ƒå¤§

**åŽŸå› **: å¹¶å‘å¤„ç†æœ¬èº«ä¸ä¼šå½±å“ç»“æžœï¼Œä½† GPT-4o çš„è¯„åˆ¤æœ¬èº«æœ‰éšæœºæ€§

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# ç¡®ä¿æ¸©åº¦ä¸º0
temperature: 0

# å¤šæ¬¡è¿è¡Œå–å¹³å‡
# è¿è¡Œ3æ¬¡ï¼Œå–ä¸­ä½æ•°
```

## ðŸ“ˆ æˆæœ¬åˆ†æž

### Token ä½¿ç”¨ï¼ˆ50ä¸ªæ ·æœ¬ï¼‰

| é…ç½® | æ€» Tokens | æˆæœ¬ (GPT-4o) | æ—¶é—´ |
|------|----------|---------------|------|
| é¡ºåºï¼Œçº¯æ–‡æœ¬ | ~25k | $0.25 | ~2åˆ†é’Ÿ |
| é¡ºåºï¼Œ8å¸§è§†é¢‘ | ~150k | $1.50 | ~4åˆ†é’Ÿ |
| å¹¶å‘(5)ï¼Œ8å¸§è§†é¢‘ | ~150k | $1.50 | ~1åˆ†é’Ÿ âš¡ |
| å¹¶å‘(10)ï¼Œ8å¸§è§†é¢‘ | ~150k | $1.50 | ~0.8åˆ†é’Ÿ âš¡âš¡ |

**é‡è¦**: å¹¶å‘ä¸å¢žåŠ  token æˆæœ¬ï¼ŒåªåŠ å¿«é€Ÿåº¦ï¼

## ðŸ”¬ æŠ€æœ¯ç»†èŠ‚

### å¹¶å‘æŽ§åˆ¶æœºåˆ¶

ä½¿ç”¨ `asyncio.Semaphore` å®žçŽ°ï¼š

```python
semaphore = asyncio.Semaphore(max_concurrent)

async def _process_single_sample(...):
    async with semaphore:  # è‡ªåŠ¨æŽ’é˜Ÿï¼Œæœ€å¤šNä¸ªåŒæ—¶è¿è¡Œ
        # å¤„ç†å•ä¸ªæ ·æœ¬
        result = await self._rank_pair(...)
        return result
```

### å¼‚å¸¸å¤„ç†

```python
# ä½¿ç”¨ asyncio.gather çš„ return_exceptions=True
results = await asyncio.gather(*tasks, return_exceptions=True)

# å•ç‹¬å¤„ç†æ¯ä¸ªç»“æžœ
for result in results:
    if isinstance(result, Exception):
        # è®°å½•é”™è¯¯ï¼Œç»§ç»­å¤„ç†å…¶ä»–ç»“æžœ
        logger.error(f"Error: {result}")
```

### æ€§èƒ½æŒ‡æ ‡

ä»£ç è‡ªåŠ¨è®°å½•ï¼š
- æ€»å¤„ç†æ—¶é—´
- å¹³å‡æ¯ä¸ªæ ·æœ¬æ—¶é—´
- æˆåŠŸ/å¤±è´¥ç»Ÿè®¡

```python
elapsed_time = time.time() - start_time
logger.info(f"Completed {len(results)} comparisons in {elapsed_time:.1f}s")
logger.info(f"Average: {elapsed_time/len(results):.1f}s per comparison")
```

## ðŸŽ“ é«˜çº§ä¼˜åŒ–

### 1. åŠ¨æ€å¹¶å‘è°ƒæ•´

æ ¹æ®é”™è¯¯çŽ‡è‡ªåŠ¨è°ƒæ•´ï¼š

```python
async def adaptive_evaluate(self, predictions, dataset):
    # ä»Žè¾ƒé«˜å¹¶å‘å¼€å§‹
    self.max_concurrent = 10
    
    while self.max_concurrent >= 1:
        try:
            result = await self.evaluate(predictions, dataset)
            error_rate = result.details['errors'] / result.details['total_samples']
            
            if error_rate < 0.05:
                return result  # æˆåŠŸ
            else:
                # é™ä½Žå¹¶å‘é‡è¯•
                self.max_concurrent = self.max_concurrent // 2
        except Exception as e:
            self.max_concurrent = self.max_concurrent // 2
```

### 2. æ‰¹å¤„ç†ç­–ç•¥

å°†å¤§ä»»åŠ¡åˆ†æ‰¹å¤„ç†ï¼š

```python
batch_size = 20
for i in range(0, len(all_samples), batch_size):
    batch = all_samples[i:i+batch_size]
    batch_results = await self.process_batch(batch)
    time.sleep(5)  # æ‰¹æ¬¡é—´ä¼‘æ¯
```

### 3. ç¼“å­˜è§†é¢‘å¸§

é¿å…é‡å¤æå–ï¼š

```python
from functools import lru_cache

@lru_cache(maxsize=100)
def _extract_video_frames_cached(self, video_path: str):
    return self._extract_video_frames(video_path)
```

## ðŸ“š ç›¸å…³æ–‡æ¡£

- [Video-Aware Ranking Guide](./VIDEO_AWARE_RANKING.md)
- [Test-50 Ranking Usage](./TEST50_RANKING_USAGE.md)
- [Azure OpenAI Rate Limits](https://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits)

## ðŸŽ‰ æ€»ç»“

é€šè¿‡å¹¶å‘å¤„ç†ï¼š
- âœ… **é€Ÿåº¦æå‡ 3-5å€**
- âœ… **ä¸å¢žåŠ æˆæœ¬**
- âœ… **ç®€å•é…ç½®**
- âœ… **è‡ªåŠ¨é”™è¯¯å¤„ç†**

åªéœ€åœ¨é…ç½®ä¸­æ·»åŠ  `max_concurrent: 5`ï¼Œå³å¯äº«å—é€Ÿåº¦æå‡ï¼

---

**æ›´æ–°æ—¥æœŸ**: 2025-11-14  
**ç‰ˆæœ¬**: 1.0  
**ä½œè€…**: VLM Benchmark Team

